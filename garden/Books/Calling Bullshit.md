---
title: "Calling Bullshit"
---

## Context

I'm reading this for my book club with my friend.

## Chapter summaries

### Preface

I agree with their opinion that people fall for things that make them feel smart, what they call "second-order bullshit". People like feeling like the insider.

**Harry Frankfurt:** bullshit is a defining characteristic of our time.

They draw a distinction between "old-school" and "new-school" bullshit. By old-school, they mean "rhetoric or fancy language". By new-school, they mean data.

> New-school bullshit uses the language of math and science and statistics to create the impression of rigor and accuracy.

So something like this:

![The Bullshit Line](garden/Books/Attachments/The%20Bullshit%20Line.png)

I disagree with the above dichotomy, because [Fuck binaries](Fuck%20binaries) and because there is too much overlap between the two modes. A less rigid model might look like this:

![The Bullshit Triangle](garden/Books/Attachments/The%20Bullshit%20Triangle.png)

This also happens to map to the [Trivium](Trivium) because I'm smart.

A lot of their problems with data bullshit are problems of **specificity**, by which I mean "people not telling you everything right away immediately". As someone with [ADHD](ADHD) I can appreciate that: we all get bored, don't we? 

The examples they give aren't great. This is because they are **extracts**. It's very easy to take a piece of writing out of context and make it seem deceptive: **you are removing the context**. The context might be necessary. For example, they cite what appears to be an extract from an oncological paper that makes some claims that they call "bullshit" on. But this writing isn't prima facie bullshit: it might just be technical. There is a difference between assumed knowledge on the part of the reader, and bullshit. Not everything needs to be [ELI5](ELI5).

> Many of us don't feel qualified to challenge information that is presented in quantitative form.

I agree with this. They also argue that often only basic logical reasoning is required to see through data bullshit: I agree with this too.

Then they get into politics, and that's where it all falls down of course. They argue that

> adequate bullshit detection is essential for the survival of liberal democracy. Democracy has always relied on a critically thinking electorate.

I fundamentally disagree with at least half of this. Democracy _in no way_ requires a critically thinking electorate. I would be interested to know their definition of "democracy", and possibly also their definition of "relied on". Arguably a foundational quality of liberal democracy is the fact that the citizen is not obligated to think critically, in any way. A bit "we shouldn't let stupid people vote" if I choose to be unfair.

They also cite Mark Galeotti, who said in a _New York Times_ op-ed that

> the United States government should teach the public to tell when they are being manipulated.

I would argue that it is not in the US government's best interests to do is, if it wants to continue as a going concern. Once manipulation is adequately defined, a lot of people see government intervention as a form of manipulation. They have a monopoly on violence, after all. 

The authors also believe that bullshit can be challenged apolitically - I would challenge their definition of "apolitical". The authors state that voters seeing through bullshit adds to the health of a democracy, which I do agree with in principle but which contradicts their claim of apoliticality. Who defines bullshit, and why? If bullshit detection is critical for the functioning of democracy, then _these are political questions_.

The purpose of education is to "improve bullshit detection", amongst other things. They argue that STEM has been prioritised over critical thinking: then why aren't people comfortable arguing statistics? Hannah is an outlier and shouldn't be counted, but most STEM-lords are happy arguing statistics all day long. I disagree with their assessment that "in STEM fields, students seldom are given paradoxes that they need to resolve, conflicting forms of evidence that they must reconcile," and so forth. Mathematics (the M part) both contains volumes of paradox, exceptions, false friends, and requires precise logical reasoning. Similarly with the sciences. I don't think the issue is that STEM students lack critical thinking: rather, I think the authors have **over**emphasised the degree to which _anyone_ has critical thinking skills, in any way.

### Chapter 1

They want to answer:

1. What is bullshit?
2. Where does bullshit come from?
3. Why is so much of it produced?

So I'll be evaluating this chapter based on how well those questions get answered.

They compare bullshitting to sophistry, being "indifferent to what is actually true and interested only in winning arguments". 

This is an interesting historical note, and worthy of study: you might ask _why_ some people are interested in winning arguments. Do they have some ulterior motive? Do they seek a _higher_ truth, or maybe not value truth as highly as other people? Is bullshit simply the manifestation of a clash of value systems?

Instead they talk about shrimp: mantis shrimp in particular, and how they sometimes pretend to still have dangerous punching power even whilst molting. But they don't _directly_ argue that this is why people spout bullshit. **One could argue** that the authors are "using the language of science to create the impression of rigor and accuracy," **couldn't one?**

They also somewhat arbitrarily assert that

> this behaviour isn't something that these creatures think up and decide to carry out. It is merely an evolved response, a sort of instinct or reflex.

Why they state this, without evidence, I have no idea. I don't think it's wrong: it's just interesting.

They talk about **theory of mind**, and bring up that ravens have a theory of mind. That's kind of neat. But yeah. Ravens can fake out other ravens while making a food cache, and can trick them into not being able to find the hidden food. That's pretty cool.

**Language** is tremendously expressive, in that we can convey a broad range of ideas. This, they claim, is one of the contributing factors to bullshit proliferation. We can say lots of different things, some of which are false, and have the theory of mind to **predict what impact they will have on other people**.

> By paying attention to communication, you are giving other people a "handle" they can use to manipulate your behavior.

They draw the distinction between bullshitters who are trying to actively deceive, and those who are indifferent to the truth. Which is interesting, and I wish they'd done that before all the chat about shrimp and ravens. That was kind of a waste of time, now, wasn't it?

Even supposedly other-regarding signals carry information about the self. When you tell a story about someone else, you're highlighting e.g. that you thought the story was of interest. This is technically true, but not interesting, and I don't think it's actually doing anything here.

They argue that **vanity generates "a lot" of bullshit**. How much? The majority?

They then go on to talk about Brandolini's principle, which is this idea from 2014(!) that 

> the amount of energy needed to refute bullshit is an order of magnitude bigger than to produce it.

Spurious use of "an order of magnitude" there. Is Brandolini "using the language of math to create the impression of rigor and accuracy"? **Who could possibly say?!**

They then go on to talk about Andrew Wakefield for a bit, and the fact that all of his claims have been widely discredited while people continue to spread bullshit about vaccines. But why did Andrew Wakefield spread the false claim that "vaccines cause autism" in the first place? 

The answer is: he didn't. He claimed specifically that the "triple-shot" MMR vaccine caused autism. And the reason that he did this is that he had a business selling single-shot MMR vaccines. He stood to make **money** off of his claim. It wasn't that Andrew Wakefield "simply didn't care about the truth". The reality is, he cared _less_ about the truth than about **making money**. He was motivated - quite simply - by greed. See for example Hbomberguy's video on the subject. This is relegated to a footnote, but it is a **major driver** of Wakefield's bullshit.

Let's assess the chapter, in light of those three questions:

1. What is bullshit?
	- This is adequately explained, I think. It's just a term: the definition can be loose enough.
2. Where does bullshit come from?
	- Under-explored: shrimp, maybe?
3. Why is so much of it produced?
	- That depends on your definition of what "why" is.
	- "Why" is so much bullshit produced? Because it's harder to get rid of than it is to produce it? No - that only explains why there's so much of it, **not** why it was produced in the first place.
	- The failure of this book to highlight power and financial motivators in its first two chapters is pretty shocking. Bullshit is _fundamentally_ political, but they've decided to study it through an apolitical lens. They're not allowing themselves to see the financial motivators. It's a shame.

#### Definitions

- **paltering** - misleading rather than directly lying
	- gives the liar a level of plausible deniability
	- only possible because of how we use language
		- **pragmatics** - implied meaning
		- **implicature** - what a sentence is used to mean, not necessarily what it _literally_ means
- **weasel wording** - using the gap between literal meaning and implicature to avoid responsibility
	- they mention advertising and politics
		- "reduce plaque by **up to** 50%"
		- "**people are saying**"
- **self-regarding signal** - a signal that refers to the signaller itself
	- e.g. "I'm sexy", "I'm poisonous"
	- they claim this is how animals typically communicate
- **other-regarding signal** - a signal that refers to some other signified
	- they claim these are uncommon among animal signals, except in cases of alarm
		- counterpoint: bees, ants, ravens, dogs
		- why are they claiming these things?
	- they argue human vocabulary is necessary for talking about things other than ourselves
		- I don't think this is necessarily true or adequately argued
